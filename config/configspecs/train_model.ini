[experiment]
exp_name = string(max=25)                                   # experiment name
tags = string_list()                                        # optional set of tags
seed = integer(default=-1)                                  # random seed
debug = boolean(default=0)                                  # If True, debugging
train = boolean(default=0)                                  # If True, train model
test = boolean(default=0)                                   # If True, test model
use_comet_logger = boolean(default=0)                       # If True, use Comet ML Logger

[data]              # Data arguments
    [[general]]         # General shared arguments
    dset = string(default="vindr_cxr")                      # Dataset to load in training/validation
    num_classes = integer(min=1, max=6, default=2)          # Number of classes/labels
    label_col = string(max=25, default="Has Finding")       # Name of binary metadata column to use as binary label
    filter_negative = boolean(default=1)                    # If True, ensure negative class contains only images with "No finding" == 1
    img_mode = integer(min=1, max=3, default=3)             # Number of image channels to load
    norm_mean = float_list()                                # Normalization means for each channel (1 if grayscale, 3 if RGB)
    norm_std = float_list()                                 # Normalization std for each channel (1, if grayscale, 3 if irgb)

    [[training]]        # Training-related arguments
    train_test_split = float(min=0, max=1, default=1)       # Prop. of total data to leave for training & validation, rest for testing
    train_val_split = float(min=0, max=1, default=0.75)     # Prop. of data after removing test for training, rest for validation
    cross_val_folds = integer(min=1, default=1)             # If >1, perform K-Fold cross-validation
    stratify_train_val_split = boolean(default=1)           # If True, perform stratified validation split
    force_train_ids = string_list()                         # List of IDs to force to be part of training

    [[augment]]         # Augmentations during training
    augment_training = boolean(default=0)                   # If True, adding augmentations during training pre-DataLoader
    crop_scale = float(min=0.01, max=1.0, default=0.3)      # Lower bound on proportion of area cropped relative to the full image.
    aug_equalize = boolean(default=0)                       # If True, perform random histogram equalization
    aug_sharpen = boolean(default=0)                        # If True, perform random sharpening
    aug_blur = boolean(default=0)                           # If True, perform random blurring
    aug_rotate = boolean(default=0)                         # If True, perform random rotation
    aug_crop = boolean(default=0)                           # If True, perform random cropping
    aug_zoomout = boolean(default=0)                        # If True, perform random zoomout

    [[dataloader]]      # Dataloader-related arguments
    batch_size = integer(min=1, default=32)                 # Batch size
    shuffle = boolean(default=0)                            # If True, shuffling data
    num_workers = integer(min=0, default=5)                 # Number of CPU workers
    imbalanced_sampler = boolean(default=0)                 # If True, perform imbalanced sampling

[model]
    [[model]]              # Model arguments
    model_provider = option("torchvision", "timm", default="torchvision")   # Name of package containing model architecture implementation
    model_name = string(max=25, default="convnext_base")    # Name of model

    [[training]]            # Training arguments
    checkpoint = boolean(default=1)                         # If True, performing checkpointing
    early_stopping = boolean(default=0)                     # If True, perform early stopping on validation loss
    precision = option("16", "bf16", "16-mixed", "bf16-mixed", "32", default="32")    # Model precision
    stop_epoch = integer(min=1, default=50)                 # Number of epochs
    use_mixup_aug = boolean(default=0)                      # If True, use MixUp augmentation during training post-DataLoader

    [[optim]]               # Optimization parameters
    optimizer = option("sgd", "adamw", default="adamw")     # Optimizer of choice
    lr = float(min=0.000001, default=0.0001)                 # Learning rate
    weight_decay = float(min=0, default=0.0005)              # Weight decay
    momentum = float(min=0, default=0.9)                    # SGD momentum
    grad_clip_norm = float(min=0, default=1.0)              # Gradient clipping norm
    swa = boolean(default=0)                                # If True, performing Stochastic Weight Averaging
    accum_batches = integer(min=1, default=1)               # Number of batches to accumulate gradient over to increase effective batch size

    [[misc]]                # Miscellaneous arguments
    torch_compile = boolean(default=0)                      # If True, using `torch.compile` on model
